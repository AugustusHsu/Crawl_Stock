{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "參考https://github.com/Asoul/tsec\n",
    "'''\n",
    "## -*- coding: utf-8 -*-\n",
    "#-*- coding: cp950 -*-\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import logging\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "'''\n",
    "定義Fuction\n",
    "'''\n",
    "\n",
    "#清除抓到的股票每個欄位中多餘的逗號還有空白\n",
    "def clean_row(row):\n",
    "    ''' Clean comma and spaces '''\n",
    "    for index, content in enumerate(row):\n",
    "        row[index] = re.sub(\",\", \"\", content.strip())\n",
    "    return row\n",
    "\n",
    "#紀錄stock_id這隻股票的資料以append的方式增加在stock_id.csv後面\n",
    "def record(stock_id, row):\n",
    "    ''' Save row to csv file '''\n",
    "    prefix=\"data\"\n",
    "    f = open('../{}/{}.csv'.format(prefix, stock_id.strip()), 'a')\n",
    "    cw = csv.writer(f, lineterminator='\\n')\n",
    "    cw.writerow(row)\n",
    "    f.close()\n",
    "    \n",
    "#初始化csv檔的column\n",
    "def Initialize(Stock_ID):\n",
    "    #初始化Stock_ID.csv\n",
    "    prefix = \"../data\"\n",
    "    if not os.path.isfile('{}/{}.csv'.format(prefix, Stock_ID.strip())):\n",
    "        ''' Save row to csv file '''\n",
    "        f = open('{}/{}.csv'.format(prefix, Stock_ID.strip()), 'a', encoding='utf-8-sig')\n",
    "        cw = csv.writer(f, lineterminator='\\n')\n",
    "        csv_Columns = ['日期','成交股數','成交金額','開盤價','最高價','最低價',\n",
    "                       '收盤價','漲跌價差','成交筆數','最後揭示買價','最後揭示賣價',]\n",
    "        cw.writerow(csv_Columns)\n",
    "        f.close()\n",
    "        \n",
    "#爬Stock_ID這支股票指定日期Day這天的資料\n",
    "def Get_TSEdata(Day, Stock_ID):\n",
    "    #設定網頁中要輸入的選項，再設定要儲存的日期格式\n",
    "    Date_str = '{0}{1:02d}{2:02d}'.format(Day.year, Day.month, Day.day)\n",
    "    Store_time = '{0}-{1:02d}-{2:02d}'.format(Day.year, Day.month, Day.day)\n",
    "    #print(Date_str)\n",
    "    url = 'http://www.twse.com.tw/exchangeReport/MI_INDEX'\n",
    "    query_params = {\n",
    "        'date': Date_str,\n",
    "        'response': 'json',\n",
    "        'type': 'ALL',\n",
    "        '_': str(round(time.time() * 1000) - 500)\n",
    "    }\n",
    "    # Get json data\n",
    "    page = requests.get(url, params=query_params)\n",
    "    for ID in Stock_ID:\n",
    "        Initialize(ID)\n",
    "    if not page.ok:\n",
    "        logging.error(\"Can not get TSE data at {}\".format(Date_str))\n",
    "    else:\n",
    "        # Parse page\n",
    "        content = page.json()\n",
    "        #print(content)\n",
    "        for attri in content:\n",
    "            #print(attri)\n",
    "            if attri == 'data5' or attri == 'data4' or attri == 'data3' or  attri == 'data2' or attri == 'data1':\n",
    "                for data in content[attri]:\n",
    "                    for ID in Stock_ID:\n",
    "                        if str(data[0]).strip() == ID:\n",
    "                            sign = '-' if data[9].find('green') > 0 else ''\n",
    "                            #print(data)\n",
    "                            row = [\n",
    "                                Store_time, # 日期\n",
    "                                data[2], # 成交股數\n",
    "                                data[4], # 成交金額\n",
    "                                data[5], # 開盤價\n",
    "                                data[6], # 最高價\n",
    "                                data[7], # 最低價\n",
    "                                data[8], # 收盤價\n",
    "                                sign + data[10], # 漲跌價差\n",
    "                                data[3], # 成交筆數\n",
    "                                data[11],#最後揭示買價\n",
    "                                data[13],#最後揭示賣價\n",
    "                            ]\n",
    "                            #print(row)\n",
    "                            clean_row(row)\n",
    "                            print(row)\n",
    "                            record(data[0], row)\n",
    "\n",
    "'''\n",
    "抓取Stock_ID在日期範圍(First_Day,Last_Day)內的所有資料\n",
    "['日期','成交股數','成交金額','開盤價','最高價','最低價','收盤價','漲跌價差','成交筆數','最後揭示買價','最後揭示賣價']\n",
    "'''\n",
    "#預設抓台積電(2330)從今天到2004,2,11的資料\n",
    "def Get_Stock_DATA(Stock_ID = [\"2330\"], First_Day = datetime.today(), Last_Day = datetime(2004,2,11)):\n",
    "    #Set Stock_ID that need to crawl\n",
    "    print(\"Crawl \" + str(Stock_ID) + \"Stock Data\")\n",
    "    #Set logging\n",
    "    if not os.path.isdir('../log'):\n",
    "        os.makedirs('../log')\n",
    "    logging.basicConfig(filename='../log/crawl-error.log',\n",
    "                        level=logging.ERROR,\n",
    "                        format='%(asctime)s\\t[%(levelname)s]\\t%(message)s',\n",
    "                        datefmt='%Y/%m/%d %H:%M:%S')\n",
    "    #Make directory if not exist when initialize\n",
    "    prefix='../data'\n",
    "    if not os.path.isdir(prefix):\n",
    "        os.mkdir(prefix)\n",
    "        \n",
    "    #The First_Day and Last_Day\n",
    "    Date_str = '{0}/{1:02d}/{2:02d}'.format(First_Day.year - 1911, First_Day.month, First_Day.day)\n",
    "    CE_Date_str = '{0}/{1:02d}/{2:02d}'.format(First_Day.year, First_Day.month, First_Day.day)\n",
    "    print(\"Start on \" + Date_str)\n",
    "    print(\"Start on \" + CE_Date_str)\n",
    "    Date_str = '{0}/{1:02d}/{2:02d}'.format(Last_Day.year - 1911, Last_Day.month, Last_Day.day)\n",
    "    CE_Date_str = '{0}/{1:02d}/{2:02d}'.format(Last_Day.year, Last_Day.month, Last_Day.day)\n",
    "    print(\"End of \" + Date_str)\n",
    "    print(\"End of \" + CE_Date_str)\n",
    "    \n",
    "    #Set Max_Error to 5\n",
    "    Max_Error = 5\n",
    "    Error_Times = 0\n",
    "    #Crawl stock until Last_Day\n",
    "    while Error_Times < Max_Error and First_Day >= Last_Day:\n",
    "        try:\n",
    "            Get_TSEdata(Last_Day, Stock_ID)\n",
    "            Error_Times = 0\n",
    "        except:\n",
    "            '''When crawl data occuring problem add one to Error_Times'''\n",
    "            date_str = Last_Day.strftime('%Y/%m/%d')\n",
    "            logging.error('Crawl raise error {}'.format(date_str))\n",
    "            Error_Times += 1\n",
    "            continue\n",
    "        finally:\n",
    "            Last_Day += timedelta(1)\n",
    "            \n",
    "    print(\"Finish\")\n",
    "\n",
    "#每日更新，去讀取資料夾內的StockID更新\n",
    "def DailyUpdate():\n",
    "    #找../data裡面有的股票資料去更新\n",
    "    DataList = os.listdir(\"../data\")\n",
    "    print(DataList[2:])\n",
    "    print(\"Update...\")\n",
    "    for CSV in DataList[2:]:\n",
    "        #讀檔去找最後一筆的日期\n",
    "        print(\"{}\".format(CSV[:-4]))\n",
    "        df = pd.read_csv(\"../data/{}.csv\".format(CSV[:-4]))\n",
    "        date = np.array(df.iloc[df.shape[0]-1:df.shape[0],:1])\n",
    "\n",
    "        strdate = str(date)\n",
    "        #最後一筆的日期\n",
    "        year = int(strdate[3:7])\n",
    "        month = int(strdate[8:10])\n",
    "        day = int(strdate[11:13])\n",
    "        Stock_ID = []\n",
    "        Stock_ID.append(CSV[:-4])\n",
    "        \n",
    "        LastUpdate = datetime(year,month,day) + timedelta(1)\n",
    "        Today = datetime.today()\n",
    "        if LastUpdate != Today:\n",
    "            LastUpdate_str = '{0}/{1:02d}/{2:02d}'.format(LastUpdate.year, LastUpdate.month, LastUpdate.day)\n",
    "            Today_str = '{0}/{1:02d}/{2:02d}'.format(Today.year, Today.month, Today.day)\n",
    "            print(\"From {} to {} (Today)\".format(LastUpdate_str, Today_str))\n",
    "            \n",
    "            #最多Error 5次\n",
    "            Max_Error = 5\n",
    "            Error_Times = 0\n",
    "            #Crawl stock until Last_Day\n",
    "            while Error_Times < Max_Error and Today >= LastUpdate:\n",
    "                try:\n",
    "                    Get_TSEdata(LastUpdate, Stock_ID)\n",
    "                    Error_Times = 0\n",
    "                except:\n",
    "                    #When crawl data occuring problem add one to Error_Times\n",
    "                    date_str = LastUpdate.strftime('%Y/%m/%d')\n",
    "                    logging.error('Crawl raise error {}'.format(date_str))\n",
    "                    Error_Times += 1\n",
    "                    continue\n",
    "                finally:\n",
    "                    LastUpdate += timedelta(1)\n",
    "        else:\n",
    "            print(\"Nothing to Update\")\n",
    "\n",
    "#回傳資料夾data內沒有的Stock_ID，可以藉由這個抓取沒在資料庫內的股票\n",
    "def CheckCSV(Stock_ID):\n",
    "    prefix = \"../data\"\n",
    "    CrawlID = []\n",
    "    for ID in Stock_ID:\n",
    "        if not os.path.isfile('{}/{}.csv'.format(prefix, ID.strip())):\n",
    "            CrawlID.append(ID)\n",
    "    #Get_Stock_DATA(CrawlID)\n",
    "    return CrawlID\n",
    "\n",
    "\n",
    "#Stock_ID = [\"2330\",\"2002\",\"3008\",'2332']\n",
    "#Stock_ID = [\"2332\"]\n",
    "#datetime(2004,2,11) data2\n",
    "#datetime(2009,1,5) data4\n",
    "#datetime(2011,8,1) data5\n",
    "#Get_Stock_DATA(Stock_ID, Last_Day = datetime.today() - timedelta(10))\n",
    "#Get_Stock_DATA(Stock_ID=Stock_ID)\n",
    "#Get_TSEdata(datetime(2009,1,5), ['3008'])\n",
    "DailyUpdate()\n",
    "Stock_ID = [\"2330\",\"2002\",\"3008\",'2332','12','123']\n",
    "CrawlID = CheckCSV(Stock_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
